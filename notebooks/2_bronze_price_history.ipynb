{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f57e9358-15a8-402b-95f2-5d05c27a0ba5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install yfinance requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7299cd78-867c-497a-a3d5-9e9dff67901d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, DateType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8a8eece-78de-48d7-b538-bea7bdebd3fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS bronze.stock_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0140bd7-9c90-4228-99dd-5d73ad6da617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"symbol\", StringType(), False),\n",
    "    StructField(\"date\", DateType(), False),\n",
    "    StructField(\"close\", DoubleType(), True),\n",
    "    StructField(\"dividends\", DoubleType(), True),\n",
    "    StructField(\"stock_splits\", DoubleType(), True),\n",
    "    StructField(\"ingestion_timestamp\", TimestampType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87c6ee62-7a67-496e-a792-e96a69d6c416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fetch_stock_data(symbol):\n",
    "    try:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        hist = ticker.history(period=\"10y\", interval=\"1wk\")\n",
    "        \n",
    "        if hist.empty:\n",
    "            return None\n",
    "            \n",
    "        hist = hist.reset_index()\n",
    "        hist['symbol'] = symbol\n",
    "        hist['ingestion_timestamp'] = datetime.now()\n",
    "        \n",
    "        return hist[['symbol', 'Date', 'Close', 'Dividends', 'Stock Splits', 'ingestion_timestamp']]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed {symbol}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31d78568-7422-480d-80c4-788c0ef73c68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tickers = spark.table(\"bronze.stock_reference.company_info\").select(\"symbol\").toPandas()['symbol'].tolist()\n",
    "\n",
    "batch_size = 100\n",
    "total_rows = 0\n",
    "\n",
    "for i in range(0, len(tickers), batch_size):\n",
    "    batch = tickers[i:i+batch_size]\n",
    "    print(f\"Batch {i//batch_size + 1}: Processing {len(batch)} stocks\")\n",
    "    \n",
    "    batch_data = []\n",
    "    for symbol in batch:\n",
    "        data = fetch_stock_data(symbol)\n",
    "        if data is not None:\n",
    "            batch_data.append(data)\n",
    "    \n",
    "    if batch_data:\n",
    "        combined = pd.concat(batch_data, ignore_index=True)\n",
    "        combined.columns = ['symbol', 'date', 'close', 'dividends', 'stock_splits', 'ingestion_timestamp']\n",
    "        \n",
    "        spark.createDataFrame(combined, schema=schema).write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .partitionBy(\"symbol\") \\\n",
    "            .saveAsTable(\"bronze.stock_data.price_history\")\n",
    "        \n",
    "        total_rows += len(combined)\n",
    "        print(f\"Saved {len(combined)} rows (Total: {total_rows})\")\n",
    "\n",
    "print(f\"\\n Complete: {total_rows} rows loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "800a76d9-ef6a-4e57-b8a4-29609ca21063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select \n",
    "    count(distinct symbol) as stocks_loaded,\n",
    "    min(date) as earliest_date,\n",
    "    max(date) as latest_date,\n",
    "    sum(case when dividends > 0 then 1 else 0 end) as dividend_payments\n",
    "from bronze.stock_data.price_history"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4764657154728486,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2_bronze_price_history",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
